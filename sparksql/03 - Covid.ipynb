{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BTogu7y3WuMV",
        "outputId": "066da28a-9802-4954-8140-8b61ada998cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Setup Spark SQL\n",
        "# Note if running locally you need the JVM https://www.oracle.com/java/technologies/downloads/\n",
        "# Also, if running locally you'll need to allow it to talk over the network to your own machine\n",
        "# Consider running in https://colab.research.google.com/\n",
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8zjIATulWuMX"
      },
      "outputs": [],
      "source": [
        "# Initialize Context - this is where you'd setup information about your Hadoop cluster if you had one!\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Covid\").getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "\n",
        "sc.setLogLevel(\"WARN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0c_HeLoEWuMY",
        "outputId": "0a55b7b7-0937-452f-bf3a-e9629c772b9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 99.9M  100 99.9M    0     0   223M      0 --:--:-- --:--:-- --:--:--  223M\n"
          ]
        }
      ],
      "source": [
        "# Download 100mb covid county data file\n",
        "!curl \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\" > ./uscounties.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MLqqsUF4WuMY",
        "outputId": "f2b7eaa8-791d-4bda-930a-b71ef053b884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+----------+-----+-----+------+\n",
            "|      date|     county|     state| fips|cases|deaths|\n",
            "+----------+-----------+----------+-----+-----+------+\n",
            "|2020-01-21|  Snohomish|Washington|53061|    1|     0|\n",
            "|2020-01-22|  Snohomish|Washington|53061|    1|     0|\n",
            "|2020-01-23|  Snohomish|Washington|53061|    1|     0|\n",
            "|2020-01-24|       Cook|  Illinois|17031|    1|     0|\n",
            "|2020-01-24|  Snohomish|Washington|53061|    1|     0|\n",
            "|2020-01-25|     Orange|California|06059|    1|     0|\n",
            "|2020-01-25|       Cook|  Illinois|17031|    1|     0|\n",
            "|2020-01-25|  Snohomish|Washington|53061|    1|     0|\n",
            "|2020-01-26|   Maricopa|   Arizona|04013|    1|     0|\n",
            "|2020-01-26|Los Angeles|California|06037|    1|     0|\n",
            "|2020-01-26|     Orange|California|06059|    1|     0|\n",
            "|2020-01-26|       Cook|  Illinois|17031|    1|     0|\n",
            "|2020-01-26|  Snohomish|Washington|53061|    1|     0|\n",
            "|2020-01-27|   Maricopa|   Arizona|04013|    1|     0|\n",
            "|2020-01-27|Los Angeles|California|06037|    1|     0|\n",
            "|2020-01-27|     Orange|California|06059|    1|     0|\n",
            "|2020-01-27|       Cook|  Illinois|17031|    1|     0|\n",
            "|2020-01-27|  Snohomish|Washington|53061|    1|     0|\n",
            "|2020-01-28|   Maricopa|   Arizona|04013|    1|     0|\n",
            "|2020-01-28|Los Angeles|California|06037|    1|     0|\n",
            "+----------+-----------+----------+-----+-----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Write code to define or infer the schema and then read in the dataset\n",
        "# Read the file into a Spark DataFrame\n",
        "usCountiesFilePath = \"./uscounties.csv\"\n",
        "from pyspark.sql.types import DateType, StringType, StructField, StructType, IntegerType\n",
        "\n",
        "# the fips column needs to be a string in order to preserve leading zeros\n",
        "schema = StructType([StructField('date', DateType(), True), StructField('county', StringType(), True), StructField('state', StringType(), True), StructField('fips', StringType(), True), StructField('cases', IntegerType(), True), StructField('deaths', IntegerType(), True)])\n",
        "\n",
        "df = spark.read.csv(usCountiesFilePath, schema=schema, header=True)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PJZ0D9BSWuMY",
        "outputId": "000162f2-758d-4fec-e545-d2b92d270c76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max deaths:\n",
            "+-------------+--------+------+\n",
            "|       county|   state|deaths|\n",
            "+-------------+--------+------+\n",
            "|New York City|New York| 40267|\n",
            "+-------------+--------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Write code to find the county with the most deaths\n",
        "# Option 1) SparkSQL API\n",
        "df.createOrReplaceTempView(\"covid\")  # create table that you can do sql on\n",
        "\n",
        "print(\"Max deaths:\")\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select county, state, deaths\n",
        "    from covid\n",
        "    order by deaths desc\n",
        "    limit 1\n",
        "  \"\"\"\n",
        ").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un4dLr7SWuMY"
      },
      "outputs": [],
      "source": [
        "# Option 2) # DataFrame style\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "print(\"Max deaths:\")\n",
        "print(\n",
        "    df.orderBy(col(\"deaths\").desc()).take(  # .where(col(\"county\") == \"New York City\") \\\n",
        "        1\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Tnf9daUWuMZ"
      },
      "outputs": [],
      "source": [
        "# # Option 3) RDD MapReduce Style without key\n",
        "rows = df.rdd\n",
        "\n",
        "\n",
        "def getMax(cumm, other):\n",
        "    if other[\"deaths\"] is not None and other[\"deaths\"] > cumm[\"deaths\"]:\n",
        "        return other\n",
        "    else:\n",
        "        return cumm\n",
        "\n",
        "\n",
        "print(\"Max deaths:\")\n",
        "print(rows.reduce(getMax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Niq8SodKWuMZ"
      },
      "outputs": [],
      "source": [
        "# # Option 4) RDD MapReduce Style with mapped tuples\n",
        "rows = df.rdd\n",
        "\n",
        "\n",
        "def getMax(cumm, other):\n",
        "    if other[0] > cumm[0]:\n",
        "        return other\n",
        "    else:\n",
        "        return cumm\n",
        "\n",
        "\n",
        "rows = rows.map(lambda r: (r[\"deaths\"] or 0, f\"{r['county']},{r['state']}\"))\n",
        "print(\"Max deaths:\")\n",
        "print(rows.reduce(getMax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag3VUpo9WuMZ"
      },
      "outputs": [],
      "source": [
        "# Write code to find the county with the most deaths\n",
        "print(\"Max deaths by county:\")\n",
        "\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ASwuQqrnWuMZ",
        "outputId": "33c51c5f-8ba6-4126-ba28-11494bf5a837",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most cases by county:\n",
            "+-----------+-------+\n",
            "|     county|  cases|\n",
            "+-----------+-------+\n",
            "|Los Angeles|2908425|\n",
            "+-----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Write code to find the county with the most cases\n",
        "print(\"Most cases by county:\")\n",
        "\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select county, cases\n",
        "    from covid\n",
        "    order by cases desc\n",
        "    limit 1\n",
        "    \"\"\"\n",
        ").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0xEfrgZ4WuMZ",
        "outputId": "f7160ed6-9e1e-4bc3-a1eb-cae85b440c2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of deaths in Utah County:\n",
            "+------+\n",
            "|deaths|\n",
            "+------+\n",
            "|   791|\n",
            "+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Write code to find the total number of deaths in Utah county\n",
        "print(\"Total number of deaths in Utah County:\")\n",
        "\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select deaths\n",
        "    from covid\n",
        "    where county = \"Utah\" and state = \"Utah\"\n",
        "    order by date desc\n",
        "    limit 1\n",
        "    \"\"\"\n",
        ").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTbHRoiLWuMZ"
      },
      "outputs": [],
      "source": [
        "# Write code to find the death rate for each state and sort the states by death rate descending\n",
        "spark.sql(\n",
        "    \"\"\"\n",
        "    with latestDateByFips as (\n",
        "      select fips, max(date) as date\n",
        "      from covid\n",
        "      group by fips\n",
        "    ), latestRowForEachFips as (\n",
        "      select county, state, cases, deaths, c.fips\n",
        "      from covid c\n",
        "      join latestDateByFips l on c.date = l.date\n",
        "    )\n",
        "\n",
        "    select state, (sum(deaths) sum(cases))\n",
        "    from latestRowForEachFips\n",
        "    group by state\n",
        "    \"\"\"\n",
        ").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2pPvp5VWuMZ"
      },
      "outputs": [],
      "source": [
        "# Write code to something else interesting with this data – your choice\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extra Credit 1 - Plot your death rate data!\n",
        "# Extra Credit 2 - Join this with other data or find something intresting in this data and plot it on a map!"
      ],
      "metadata": {
        "id": "HASapzHvXF5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This example uses two-letter state code\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "data = pd.DataFrame({\n",
        "  'state': ['NY', 'CA', 'TX', 'FL'],\n",
        "  'values': [10, 20, 15, 25]\n",
        "})\n",
        "\n",
        "fig = px.choropleth(\n",
        "    data,\n",
        "    locations='state', # Column with state abbreviations\n",
        "    locationmode='USA-states', # Set location mode to US states\n",
        "    color='values', # Column to determine color intensity\n",
        "    scope='usa', # Limit map to the USA\n",
        "    color_continuous_scale='Viridis', # Choose a color scale\n",
        "    title='Extra Credit Plot <Insert name here>'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "s4tCU11zhjJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This example uses the FIPS code to map data to a county\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Example county-level data (FIPS codes are required for county-level plots)\n",
        "data = pd.DataFrame({\n",
        "    'fips': ['36061', '06037', '48201', '12086'],  # Example FIPS codes (NYC, LA, Houston, Miami-Dade)\n",
        "    'values': [10, 20, 15, 25]\n",
        "})\n",
        "\n",
        "# Plot county-level choropleth map\n",
        "fig = px.choropleth(\n",
        "    data,\n",
        "    geojson=\"https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json\",  # GeoJSON for counties\n",
        "    locations='fips',  # Use county FIPS codes\n",
        "    color='values',  # Column to determine color intensity\n",
        "    color_continuous_scale='Viridis',\n",
        "    scope='usa',\n",
        "    title='County-Level Extra Credit Plot'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "IjH6Dq8saDY8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}